livelex ideas

A document of text is lexed into tokens. The tokens are saved in two ways: 
attached to the line of text, and in a tree structure.

It is always possible to alter the text, and to resume parsing at the end of 
the last token before the place the text is altered.

Each token has:
– a pos attribute where it is in the current line
– a parent attribute pointing to the context that created it


Tree structure of contexts and tokens

context has children
children can be a context or token

token is a single piece of text; can’t have children

token and context also have a pointer to the parent.

The context lexes a stream into tokens, using rulesets.

A ruleset is a flexible list of rules, where the order may be arbitrary, but it 
can also be specified that the order is fixed and that items may be skipped, or 
can occur only once etc. There can also be multiple rulesets in a context.

How a context chooses the rulesets is based on the children the context already 
has. So you can just start somewhere lexing alterations to the text, and the 
same rules will apply.

The context chooses a ruleset, and tries to match the text using all rules in 
order.

The context can only choose the ruleset based on known information. Normally 
every context just has one ruleset.

If a rule matches, a token is generated.

If the rule creates a new context as a child of the current, that context is 
added, and then the token is added to the new context.

If the rule ends a context, the token is still added to the current context, 
where it becomes the last token, and it gets a special marking to indicate new 
tokens can’t be added after this one.


In general music:

c’8

c → singlemusicevent→noteevent→pitch

pitch
 context:
    - rule find octave (if no octave and no octavecheck)
    - rule find octavecheck (if no octavecheck)
    - rule pop

noteevent:
 context:
    - rule duration
    - rule pop


music:
- notename → pitch

pitch: octave? octavecheck?


lexing:

a context consists of rules
every rule can instantiate one token
the token has the name of the rule and the context as parent
if one token is encountered, it is always instantiated. No looking forward.

problems:
- how to determine which tokens need not be parsed again
- and determine whether adjacent contexts of the same type can be concatenated

maybe it's better to just create tokens and give them a state, and leave
the creation of a tree to a different step




language:
- has named contexts (unordered)
  one context is the starting context (e.g. named 'root')

context:
- has a name, that is added on top of the state when a context is entered.
- has an ordered list of rules, (can include rules from other contexts)
- has some other properties (e.g.:
    - a default action in case of no match
    - whether the rules should match in order

rule:
- each rule has:
    - a pattern
    - a token type
    - an action (default: do nothing)
    ...some other properties, like:
        - whether the rule should apply: 0-, 1- or exactly 1 etc

A context creates a regex pattern for all the rules in one go. If there
are special cases, like fixed order or restrictions on the number of matches,
a sub-context is created with its own pattern.

While creating the rules list, a context knows beforehand which sub-contexts
could be requested and gives them a name or number.


The lexer is a simple object, fast to instantiate.
The state is a hashable tuple.
Every item in a state corresponds with a context.
The state is yielded together with every token.
A lexer is instantiated with a state, it picks the topmost context and starts
parsing.



state is a tuple like (root, comment, directive, 0, )

those refer to singleton objects, that are context/ruleset objects. Other
things like strings or numbers are hashable arguments/values for the underlying
object.

A rule can point to another context, which can be part of another language.
A new-state command can also supply arguments.

A context that starts parsing can accept arguments, that are only kept while
parsing is active. If the state is requested, those arguments are added on top
of the state.


class Language:

    root = Context(
        ('pattern', action, state),
        
        )
